import pandas as pd
import numpy as np
import pickle
import os
from sklearn.metrics import f1_score, precision_score, recall_score

# =========================================================
# 1. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# =========================================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_FILE = os.path.join(BASE_DIR, "kovo_analysis_ready.csv")
MODEL_FILE = os.path.join(BASE_DIR, "kovo_dual_model.pkl")

def get_standardized_name(name):
    if pd.isna(name): return ""
    name_upper = str(name).upper().replace(" ", "")
    mapping = {
        'ëŒ€í•œí•­ê³µ': ['KOREANAIR', 'JUMBOS', 'KAL', 'ëŒ€í•œí•­ê³µ'],
        'í˜„ëŒ€ìºí”¼íƒˆ': ['HYUNDAICAPITAL', 'SKYWALKERS', 'í˜„ëŒ€ìºí”¼íƒˆ'],
        'KBì†í•´ë³´í—˜': ['KBSTARS', 'KBINSURANCE', 'LIG', 'KBì†í•´ë³´í—˜'],
        'OKê¸ˆìœµê·¸ë£¹': ['OKFINANCIAL', 'OKSAVINGS', 'OKMAN', 'OKê¸ˆìœµ', 'ìë§¨'],
        'í•œêµ­ì „ë ¥': ['KEPCO', 'VIXTORM', 'KOREAELECTRIC', 'í•œêµ­ì „ë ¥'],
        'ìš°ë¦¬ì¹´ë“œ': ['WOORICARD', 'WOORIWON', 'ìš°ë¦¬ì¹´ë“œ'],
        'ì‚¼ì„±í™”ì¬': ['SAMSUNG', 'BLUEFANGS', 'ì‚¼ì„±í™”ì¬'],
        'í¥êµ­ìƒëª…': ['HEUNGKUK', 'PINKSPIDERS', 'í¥êµ­ìƒëª…'],
        'í˜„ëŒ€ê±´ì„¤': ['HYUNDAIE&C', 'HILLSTATE', 'í˜„ëŒ€ê±´ì„¤'],
        'ì •ê´€ì¥': ['JUNGKWANJANG', 'REDSPARKS', 'KGC', 'ì •ê´€ì¥'],
        'IBKê¸°ì—…ì€í–‰': ['IBK', 'ALTOS', 'ê¸°ì—…ì€í–‰'],
        'GSì¹¼í…ìŠ¤': ['GSCALTEX', 'KIXX', 'GSì¹¼í…ìŠ¤'],
        'ë„ë¡œê³µì‚¬': ['HIPASS', 'EXPRESSWAY', 'ë„ë¡œê³µì‚¬'],
        'í˜í¼ì €ì¶•ì€í–‰': ['PEPPER', 'AIPEPPERS', 'í˜í¼ì €ì¶•ì€í–‰']
    }
    for std, keys in mapping.items():
        if any(k in name_upper for k in keys): return std
    return name

def analyze_thresholds():
    print("ğŸš€ ìŠ¹ë¥  êµ¬ê°„ë³„ ìŠ¤ì½”ì–´ ë¶„í¬ ë¶„ì„ & ìµœì  ì„ê³„ê°’ ì°¾ê¸°")
    print("-" * 60)

    # 1. ëª¨ë¸ ë¡œë“œ
    if not os.path.exists(MODEL_FILE):
        print("âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    with open(MODEL_FILE, "rb") as f: pkg = pickle.load(f)
    clf = pkg['classifier']
    scaler = pkg['scaler']
    features = pkg['features']

    # 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (í•™ìŠµë•Œì™€ ë™ì¼)
    df = pd.read_csv(DATA_FILE)
    if 'set_score' in df.columns: df.rename(columns={'set_score': 'score'}, inplace=True)
    if 'team_name' in df.columns: df.rename(columns={'team_name': 'tsname'}, inplace=True)
    
    df['tsname'] = df['tsname'].astype(str)
    df['team_std'] = df['tsname'].apply(get_standardized_name)
    df['game_date'] = pd.to_datetime(df['game_date'])
    df = df.sort_values(['game_date', 'game_num'])

    for c in ['ats', 'att', 'bs', 'ss', 'err', 'rs', 'rt']:
        if c in df.columns: df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)

    # íŒ€ë³„ ì§‘ê³„
    team_grp = df.groupby(['game_date', 'game_num', 'team_std']).agg({
        'ats': 'sum', 'att': 'sum', 'bs': 'sum', 'ss': 'sum', 'err': 'sum', 
        'rs': 'sum', 'rt': 'sum', 'home_team': 'first', 'score': 'first'
    }).reset_index()

    team_grp['attack_rate'] = team_grp.apply(lambda x: x['ats']/x['att'] if x['att']>0 else 0, axis=1)
    team_grp['receive_rate'] = team_grp.apply(lambda x: x['rs']/x['rt'] if x['rt']>0 else 0, axis=1)
    
    team_grp['home_team_std'] = team_grp['home_team'].apply(get_standardized_name)
    team_grp['is_home'] = team_grp['team_std'] == team_grp['home_team_std']
    
    # ë¡¤ë§ í‰ê·  ê³„ì‚°
    team_grp = team_grp.sort_values(['team_std', 'game_date'])
    metrics = ['attack_rate', 'bs', 'ss', 'err', 'receive_rate']
    for m in metrics:
        team_grp[f'roll_{m}'] = team_grp.groupby('team_std')[m].transform(lambda x: x.shift(1).rolling(5, min_periods=1).mean())

    # ë§¤ì¹˜ì—… ìƒì„±
    elo = {t: 1500 for t in team_grp['team_std'].unique()}
    matches = []
    
    sorted_games = team_grp.sort_values(['game_date', 'game_num'])
    for _, grp in sorted_games.groupby(['game_date', 'game_num']):
        if len(grp) != 2: continue
        
        h_rows = grp[grp['is_home'] == True]
        a_rows = grp[grp['is_home'] == False]
        if h_rows.empty or a_rows.empty: continue
        
        h, a = h_rows.iloc[0], a_rows.iloc[0]
        th, ta = h['team_std'], a['team_std']
        
        # ì‹¤ì œ ê²°ê³¼ ë¶„ì„
        try:
            s = list(map(int, str(h['score']).split(':')))
            real_score_diff = s[0] - s[1] # 3, 2, 1, -1, -2, -3
        except: continue
        
        match_data = {
            'diff_elo': elo[th] - elo[ta],
            'diff_att': h['roll_attack_rate'] - a['roll_attack_rate'],
            'diff_block': h['roll_bs'] - a['roll_bs'],
            'diff_serve': h['roll_ss'] - a['roll_ss'],
            'diff_recv': h['roll_receive_rate'] - a['roll_receive_rate'],
            'diff_fault': h['roll_err'] - a['roll_err'],
            'real_diff': real_score_diff # +3ì´ë©´ í™ˆ 3:0 ìŠ¹, -3ì´ë©´ ì›ì • 3:0 ìŠ¹
        }
        matches.append(match_data)
        
        # ELO Update
        w_h = 1 if real_score_diff > 0 else 0
        exp_h = 1 / (1 + 10 ** ((elo[ta] - elo[th]) / 400))
        elo[th] += 20 * (w_h - exp_h)
        elo[ta] += 20 * ((1 - w_h) - (1 - exp_h))

    # ë¶„ì„ìš© ë°ì´í„°í”„ë ˆì„
    df_m = pd.DataFrame(matches).dropna()
    df_m['diff_fault'] = -df_m['diff_fault'] # ë°˜ì „
    
    X = df_m[features]
    X_scaled = pd.DataFrame(scaler.transform(X), columns=features)
    
    # ìŠ¹ë¦¬ í™•ë¥  ì˜ˆì¸¡
    probs = clf.predict_proba(X_scaled)[:, 1]
    df_m['prob_home'] = probs
    
    # =========================================================
    # ğŸ“Š 1. [Grid Search] ìŠ¹ë¥  êµ¬ê°„ë³„ ì‹¤ì œ ìŠ¤ì½”ì–´ ë¹„ìœ¨
    # =========================================================
    print("\nğŸ“Š 1. ìŠ¹ë¥  êµ¬ê°„ë³„ ìŠ¤ì½”ì–´ ì¶œí˜„ ë¹ˆë„ (Grid Search)")
    print(f"{'Prob Range':<15} | {'Games':<5} | {'3:0(%)':<8} | {'3:1(%)':<8} | {'3:2(%)':<8} | {'Upset(%)'}")
    print("-" * 75)
    
    bins = [0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 1.00]
    labels = ["50~55%", "55~60%", "60~65%", "65~70%", "70~75%", "75%~"]
    
    # í™ˆ ìŠ¹ë¦¬ ì˜ˆì¸¡ì¸ ê²½ê¸°ë§Œ í•„í„°ë§ (ìŠ¹ë¥  > 0.5)
    home_wins_pred = df_m[df_m['prob_home'] > 0.5].copy()
    home_wins_pred['prob_bin'] = pd.cut(home_wins_pred['prob_home'], bins=bins, labels=labels)
    
    for label in labels:
        subset = home_wins_pred[home_wins_pred['prob_bin'] == label]
        total = len(subset)
        if total == 0: continue
        
        cnt_30 = len(subset[subset['real_diff'] == 3])
        cnt_31 = len(subset[subset['real_diff'] == 2])
        cnt_32 = len(subset[subset['real_diff'] == 1])
        cnt_loss = len(subset[subset['real_diff'] < 0]) # ì—­ë°° í„°ì§
        
        print(f"{label:<15} | {total:<5} | {cnt_30/total*100:>6.1f}%  | {cnt_31/total*100:>6.1f}%  | {cnt_32/total*100:>6.1f}%  | {cnt_loss/total*100:>6.1f}%")

    # =========================================================
    # ğŸ¯ 2. [Optimizer] F1-Score ê¸°ë°˜ ìµœì  ì„ê³„ê°’ ì°¾ê¸°
    # =========================================================
    print("\n\nğŸ¯ 2. ìµœì  ì„ê³„ê°’ íƒìƒ‰ (F1-Score Maximization)")
    
    # (1) 3:0 ì…§ì•„ì›ƒ ê¸°ì¤€ì„  ì°¾ê¸°
    # íƒ€ê²Ÿ: ì‹¤ì œë¡œ 3:0ì¸ ê²½ê¸° (True) vs ë‚˜ë¨¸ì§€ (False)
    y_true_30 = (home_wins_pred['real_diff'] == 3).astype(int)
    probs_win = home_wins_pred['prob_home']
    
    best_th_30 = 0.5
    best_f1_30 = 0
    
    # 0.50ë¶€í„° 0.90ê¹Œì§€ 0.01 ë‹¨ìœ„ë¡œ ìŠ¤ìº”
    for th in np.arange(0.50, 0.90, 0.01):
        y_pred = (probs_win >= th).astype(int)
        score = f1_score(y_true_30, y_pred, zero_division=0)
        if score > best_f1_30:
            best_f1_30 = score
            best_th_30 = th
            
    print(f"   ğŸ† [3:0 ì…§ì•„ì›ƒ] ìµœì  í™•ë¥  ê¸°ì¤€: {best_th_30*100:.1f}% ì´ìƒ")
    print(f"      (ì´ ê¸°ì¤€ì¼ ë•Œ F1-Scoreê°€ {best_f1_30:.3f}ë¡œ ìµœëŒ€)")

    # (2) 3:2 ì ‘ì „ ê¸°ì¤€ì„  ì°¾ê¸°
    # íƒ€ê²Ÿ: ì‹¤ì œë¡œ 3:2ì¸ ê²½ê¸° (True) vs ë‚˜ë¨¸ì§€
    # ì£¼ì˜: ìŠ¹ë¥ ì´ 'ë‚®ì„ìˆ˜ë¡' 3:2 í™•ë¥ ì´ ë†’ìœ¼ë¯€ë¡œ, "ì´ í™•ë¥  ì´í•˜ë©´ 3:2ë‹¤"ë¥¼ ì°¾ì•„ì•¼ í•¨
    y_true_32 = (home_wins_pred['real_diff'] == 1).astype(int)
    
    best_th_32 = 0.6
    best_f1_32 = 0
    
    for th in np.arange(0.50, 0.70, 0.01):
        y_pred = (probs_win <= th).astype(int) # í™•ë¥ ì´ thë³´ë‹¤ 'ì‘ìœ¼ë©´' 3:2 ì˜ˆì¸¡
        score = f1_score(y_true_32, y_pred, zero_division=0)
        if score > best_f1_32:
            best_f1_32 = score
            best_th_32 = th
            
    print(f"   ğŸ† [3:2 í’€ì„¸íŠ¸] ìµœì  í™•ë¥  ê¸°ì¤€: {best_th_32*100:.1f}% ë¯¸ë§Œ")
    print(f"      (ì´ ê¸°ì¤€ì¼ ë•Œ F1-Scoreê°€ {best_f1_32:.3f}ë¡œ ìµœëŒ€)")
    
    print("\n   ğŸ’¡ [ê²°ë¡ : ì¶”ì²œ ê°€ì´ë“œë¼ì¸]")
    print(f"      - ìŠ¹ë¥  {best_th_32*100:.0f}% ë¯¸ë§Œ : 3:2 ì ‘ì „ (ì˜¤ë²„/í•¸ë””ìº¡ ì¶”ì²œ)")
    print(f"      - ìŠ¹ë¥  {best_th_32*100:.0f}% ~ {best_th_30*100:.0f}% : 3:1 ìš°ì„¸ (ì¼ë°˜ìŠ¹ ì¶”ì²œ)")
    print(f"      - ìŠ¹ë¥  {best_th_30*100:.0f}% ì´ìƒ : 3:0 ì••ìŠ¹ (ë§ˆí•¸/ì–¸ë” ì¶”ì²œ)")

if __name__ == "__main__":
    analyze_thresholds()