import pandas as pd
import numpy as np
import pickle
import sys
import os
from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score

# =========================================================
# 1. ì„¤ì • ë° ìœ í‹¸ë¦¬í‹°
# =========================================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_FILE = os.path.join(BASE_DIR, "kovo_analysis_ready.csv")
MODEL_FILE = os.path.join(BASE_DIR, "kovo_dual_model.pkl")

def get_standardized_name(name):
    if pd.isna(name): return ""
    name_upper = str(name).upper().replace(" ", "")
    mapping = {
        'ëŒ€í•œí•­ê³µ': ['KOREANAIR', 'JUMBOS', 'KAL', 'ëŒ€í•œí•­ê³µ', 'ì ë³´ìŠ¤'],
        'í˜„ëŒ€ìºí”¼íƒˆ': ['HYUNDAICAPITAL', 'SKYWALKERS', 'í˜„ëŒ€ìºí”¼íƒˆ'],
        'KBì†í•´ë³´í—˜': ['KBSTARS', 'KBINSURANCE', 'LIG', 'KBì†í•´ë³´í—˜'],
        'OKê¸ˆìœµê·¸ë£¹': ['OKFINANCIAL', 'OKSAVINGS', 'OKMAN', 'OKê¸ˆìœµ', 'ìë§¨'],
        'í•œêµ­ì „ë ¥': ['KEPCO', 'VIXTORM', 'KOREAELECTRIC', 'í•œêµ­ì „ë ¥'],
        'ìš°ë¦¬ì¹´ë“œ': ['WOORICARD', 'WOORIWON', 'ìš°ë¦¬ì¹´ë“œ', 'ìœ„ë¹„'],
        'ì‚¼ì„±í™”ìž¬': ['SAMSUNG', 'BLUEFANGS', 'ì‚¼ì„±í™”ìž¬'],
        'í¥êµ­ìƒëª…': ['HEUNGKUK', 'PINKSPIDERS', 'í¥êµ­ìƒëª…'],
        'í˜„ëŒ€ê±´ì„¤': ['HYUNDAIE&C', 'HILLSTATE', 'í˜„ëŒ€ê±´ì„¤'],
        'ì •ê´€ìž¥': ['JUNGKWANJANG', 'REDSPARKS', 'KGC', 'ì •ê´€ìž¥'],
        'IBKê¸°ì—…ì€í–‰': ['IBK', 'ALTOS', 'ê¸°ì—…ì€í–‰'],
        'GSì¹¼í…ìŠ¤': ['GSCALTEX', 'KIXX', 'GSì¹¼í…ìŠ¤'],
        'ë„ë¡œê³µì‚¬': ['HIPASS', 'EXPRESSWAY', 'ë„ë¡œê³µì‚¬'],
        'íŽ˜í¼ì €ì¶•ì€í–‰': ['PEPPER', 'AIPEPPERS', 'íŽ˜í¼ì €ì¶•ì€í–‰']
    }
    for std, keys in mapping.items():
        if any(k in name_upper for k in keys): return std
    return name

def train_stats_pro_model():
    print("ðŸš€ Step 4: [í†µê³„ì  ì ‘ê·¼] ë‹¤ì¤‘ê³µì„ ì„± í•´ê²° ë° ê³ ê¸‰ ëª¨ë¸ë§ (Pro Ver.)")

    # 1. ë°ì´í„° ë¡œë“œ
    if not os.path.exists(DATA_FILE):
        print(f"âŒ ë°ì´í„° íŒŒì¼ ì—†ìŒ: {DATA_FILE}")
        return

    df = pd.read_csv(DATA_FILE)
    if 'set_score' in df.columns: df.rename(columns={'set_score': 'score'}, inplace=True)
    if 'team_name' in df.columns: df.rename(columns={'team_name': 'tsname'}, inplace=True)

    df['game_date'] = pd.to_datetime(df['game_date'])
    df['team_std'] = df['tsname'].apply(get_standardized_name)
    df = df.sort_values(['game_date', 'game_num'])

    # ìˆ«ìž ë³€í™˜
    cols = ['ats', 'att', 'bs', 'ss', 'err', 'rs', 'rt', 'point']
    for c in cols:
        if c in df.columns: df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)

    # íŒ€ë³„ ì§‘ê³„
    team_grp = df.groupby(['game_date', 'game_num', 'team_std']).agg({
        'ats': 'sum', 'att': 'sum', 'bs': 'sum', 'ss': 'sum', 'err': 'sum', 
        'rs': 'sum', 'rt': 'sum', 'home_team': 'first', 'score': 'first'
    }).reset_index()

    # íŒŒìƒ ë³€ìˆ˜
    team_grp['attack_rate'] = team_grp.apply(lambda x: x['ats']/x['att'] if x['att']>0 else 0, axis=1)
    team_grp['receive_rate'] = team_grp.apply(lambda x: x['rs']/x['rt'] if x['rt']>0 else 0, axis=1)
    team_grp['is_home'] = team_grp.apply(lambda r: r['team_std'] == get_standardized_name(r['home_team']), axis=1)

    # íƒ€ê²Ÿ ì„¤ì •
    def check_win_diff(row):
        try:
            s = list(map(int, str(row['score']).split(':')))
            if len(s)<2: return 0, 0
            my, opp = (s[0], s[1]) if row['is_home'] else (s[1], s[0])
            return (1 if my > opp else 0), (my - opp)
        except: return 0, 0

    team_grp[['is_win', 'set_diff']] = team_grp.apply(lambda r: pd.Series(check_win_diff(r)), axis=1)

    # ë¡¤ë§ ìŠ¤íƒ¯ & ELO
    team_grp = team_grp.sort_values(['team_std', 'game_date'])
    metrics = ['attack_rate', 'bs', 'ss', 'err', 'receive_rate']
    for m in metrics:
        team_grp[f'roll_{m}'] = team_grp.groupby('team_std')[m].transform(lambda x: x.shift(1).rolling(5, min_periods=1).mean())

    elo = {t: 1500 for t in team_grp['team_std'].unique()}
    matches = []

    sorted_games = team_grp.sort_values(['game_date', 'game_num'])
    
    for _, grp in sorted_games.groupby(['game_date', 'game_num']):
        if len(grp) != 2: continue
        h_rows = grp[grp['is_home'] == True]
        a_rows = grp[grp['is_home'] == False]
        if h_rows.empty or a_rows.empty: continue
        
        h, a = h_rows.iloc[0], a_rows.iloc[0]
        th, ta = h['team_std'], a['team_std']
        
        matches.append({
            'diff_elo': elo[th] - elo[ta],
            'diff_att': h['roll_attack_rate'] - a['roll_attack_rate'],
            'diff_block': h['roll_bs'] - a['roll_bs'],
            'diff_serve': h['roll_ss'] - a['roll_ss'],
            'diff_recv': h['roll_receive_rate'] - a['roll_receive_rate'],
            'diff_fault': h['roll_err'] - a['roll_err'], 
            'result_win': h['is_win'],
            'result_diff': h['set_diff']
        })
        
        w_h = h['is_win']
        exp_h = 1 / (1 + 10 ** ((elo[ta] - elo[th]) / 400))
        elo[th] += 20 * (w_h - exp_h)
        elo[ta] += 20 * ((1 - w_h) - (1 - exp_h))

    train_df = pd.DataFrame(matches).dropna()
    
    # =========================================================================
    # ðŸ§ª [Advanced] ë‹¤ì¤‘ê³µì„ ì„± í•´ê²° ë° ê³ ê¸‰ í”¼ì²˜ ìƒì„±
    # =========================================================================
    print("ðŸ”¬ ê³ ê¸‰ í†µê³„ì  í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ìˆ˜í–‰ ì¤‘...")
    
    # 1. ë²”ì‹¤ ë°˜ì „ (ìŒìˆ˜ -> ì–‘ìˆ˜: í´ìˆ˜ë¡ ë²”ì‹¤ ì ì–´ì„œ ì¢‹ì€ ê²ƒ)
    train_df['diff_fault_inv'] = -train_df['diff_fault'] 

    # 2. ì§êµí™” (Orthogonalization) - ELO ì˜í–¥ ì œê±°í•œ ìˆœìˆ˜ ìŠ¤íƒ¯
    # 
    
    # (1) ìˆœìˆ˜ ê³µê²©ë ¥
    reg_att = LinearRegression()
    reg_att.fit(train_df[['diff_elo']], train_df['diff_att'])
    train_df['pure_att'] = train_df['diff_att'] - reg_att.predict(train_df[['diff_elo']])

    # (2) ìˆœìˆ˜ ë¸”ë¡œí‚¹
    reg_blk = LinearRegression()
    reg_blk.fit(train_df[['diff_elo']], train_df['diff_block'])
    train_df['pure_block'] = train_df['diff_block'] - reg_blk.predict(train_df[['diff_elo']])
    
    # 3. ìƒí˜¸ìž‘ìš© í•­ (ê°•íŒ€ê°„ ëŒ€ê²° ë³€ìˆ˜)
    train_df['inter_elo_att'] = train_df['diff_elo'] * train_df['diff_att'] / 1000 
    
    # 4. ìµœì¢… í•™ìŠµ í”¼ì²˜ ì„ ì •
    features = [
        'diff_elo',       # íŒ€ ì²´ê¸‰
        'pure_att',       # ìˆœìˆ˜ ê³µê²© í¼ (ELOì™€ ë…ë¦½ì )
        'pure_block',     # ìˆœìˆ˜ ë¸”ë¡œí‚¹ í¼
        'diff_serve',     # ì„œë¸Œ
        'diff_recv',      # ë¦¬ì‹œë¸Œ
        'diff_fault_inv', # ë²”ì‹¤ ê´€ë¦¬ (ë°˜ì „ë¨)
        'inter_elo_att'   # ìƒí˜¸ìž‘ìš©
    ]
    
    X = train_df[features]
    y = train_df['result_win']
    y_reg = train_df['result_diff']
    
    scaler = StandardScaler()
    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=features)
    
    # 5. ëª¨ë¸ í•™ìŠµ (L2 ê·œì œ ì ìš©)
    clf = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', random_state=42)
    clf.fit(X_scaled, y)
    
    # ê²€ì¦
    cv_score = np.mean(cross_val_score(clf, X_scaled, y, cv=5, scoring='accuracy'))
    print(f"ðŸ“Š 5-Fold êµì°¨ê²€ì¦ ì •í™•ë„: {cv_score*100:.2f}%")
    
    # ê°€ì¤‘ì¹˜ í™•ì¸
    print("\nðŸ” [ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¶„ì„]")
    for f, w in zip(features, clf.coef_[0]):
        print(f"   - {f}: {w:.4f}")
        
    # ì ìˆ˜ì°¨ ì˜ˆì¸¡ ëª¨ë¸ (Ridge)
    reg_model = Ridge(alpha=1.0)
    reg_model.fit(X_scaled, y_reg)

    # 6. ì €ìž¥ (ì§êµí™” ëª¨ë¸ í¬í•¨)
    save_pkg = {
        'classifier': clf,
        'regressor': reg_model,
        'scaler': scaler,
        'features': features,
        'is_constrained': False, 
        'is_advanced': True,
        'ortho_models': { 'att': reg_att, 'blk': reg_blk }
    }
    
    with open(MODEL_FILE, "wb") as f:
        pickle.dump(save_pkg, f)
    print(f"\nðŸ’¾ ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: {MODEL_FILE}")

    # =========================================================================
    # ðŸ§ª [ë³´ë„ˆìŠ¤] ìµœì ì˜ ìŠ¤ì½”ì–´ ìž„ê³„ê°’(Threshold) ì°¾ê¸°
    # =========================================================================
    print("\nðŸ” [Grid Search] ìµœì ì˜ ìŠ¤ì½”ì–´ êµ¬ë¶„ ê¸°ì¤€(Threshold) ê³„ì‚°...")
    
    # í•™ìŠµëœ ëª¨ë¸ë¡œ í™•ë¥  ë‹¤ì‹œ ë½‘ê¸°
    probs = clf.predict_proba(X_scaled)[:, 1]
    
    analysis_df = pd.DataFrame({
        'prob': probs,
        'win': y,
        'set_diff': y_reg # ì‹¤ì œ ì„¸íŠ¸ ë“ì‹¤
    })
    
    # ìŠ¹ë¦¬í•œ ê²½ê¸°(í™ˆìŠ¹)ë§Œ ë¶„ì„
    wins = analysis_df[analysis_df['win'] == 1]
    
    # 3:0 ìŠ¹ë¦¬ (ì„¸íŠ¸ë“ì‹¤ 3.0ì— ê°€ê¹Œìš´) vs 3:2 ìŠ¹ë¦¬ (ì„¸íŠ¸ë“ì‹¤ 1.0ì— ê°€ê¹Œìš´)
    # ìƒìœ„ 30% ì ìˆ˜ì°¨ -> ì…§ì•„ì›ƒìœ¼ë¡œ ê°„ì£¼
    # í•˜ìœ„ 30% ì ìˆ˜ì°¨ -> ì ‘ì „ìœ¼ë¡œ ê°„ì£¼
    
    t_shutout = wins[wins['set_diff'] >= wins['set_diff'].quantile(0.7)]['prob'].mean()
    t_close = wins[wins['set_diff'] <= wins['set_diff'].quantile(0.3)]['prob'].mean()
    
    print(f"   ðŸ“Š ë°ì´í„° ë¶„ì„ ê²°ê³¼:")
    print(f"      - ì…§ì•„ì›ƒ(3:0) ê²½ê¸°ë“¤ì˜ í‰ê·  í™•ë¥ : {t_shutout*100:.1f}%")
    print(f"      - í’€ì„¸íŠ¸(3:2) ê²½ê¸°ë“¤ì˜ í‰ê·  í™•ë¥ : {t_close*100:.1f}%")
    
    # ê¸°ì¤€ì  ìž¡ê¸° (ì¤‘ê°„ê°’)
    cut_30 = (t_shutout + 0.60) / 2 # 3:0 ê¸°ì¤€ (ë³´ìˆ˜ì  ë³´ì •)
    cut_31 = (t_close + 0.50) / 2   # 3:1 ê¸°ì¤€
    
    print(f"   ðŸ’¡ ì¶”ì²œ ìž„ê³„ê°’ ì ìš©: {cut_31*100:.0f}% (3:2 êµ¬ê°„) / {cut_30*100:.0f}% (3:1 êµ¬ê°„)")
    print("-" * 60)

if __name__ == "__main__":
    train_stats_pro_model()