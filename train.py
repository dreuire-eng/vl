import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression, Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, StratifiedKFold
import pickle
import sys
import os

# =========================================================
# 1. ê³µí†µ ì „ì²˜ë¦¬ ë¡œì§ (ê·¸ëŒ€ë¡œ ìœ ì§€)
# =========================================================
def get_standardized_name(name):
    name_upper = str(name).upper().replace(" ", "")
    mapping = {
        'ëŒ€í•œí•­ê³µ': ['KOREANAIR', 'JUMBOS', 'ëŒ€í•œí•­ê³µ', 'ì ë³´ìŠ¤', 'KAL'],
        'í˜„ëŒ€ìºí”¼íƒˆ': ['HYUNDAICAPITAL', 'SKYWALKERS', 'í˜„ëŒ€ìºí”¼íƒˆ', 'ìŠ¤ì¹´ì´ì›Œì»¤ìŠ¤'],
        'KBì†í•´ë³´í—˜': ['KBSTARS', 'KBINSURANCE', 'LIG', 'KBì†í•´ë³´í—˜', 'ì¼€ì´ë¹„'],
        'OKê¸ˆìœµê·¸ë£¹': ['OKFINANCIAL', 'OKSAVINGS', 'OKMAN', 'OKê¸ˆìœµ', 'ìë§¨'],
        'í•œêµ­ì „ë ¥': ['KEPCO', 'VIXTORM', 'KOREAELECTRIC', 'í•œêµ­ì „ë ¥', 'ë¹…ìŠ¤í†°'],
        'ìš°ë¦¬ì¹´ë“œ': ['WOORICARD', 'WOORIWON', 'ìš°ë¦¬ì¹´ë“œ', 'ìœ„ë¹„'],
        'ì‚¼ì„±í™”ì¬': ['SAMSUNG', 'BLUEFANGS', 'ì‚¼ì„±í™”ì¬', 'ë¸”ë£¨íŒ¡ìŠ¤'],
        'í¥êµ­ìƒëª…': ['HEUNGKUK', 'PINKSPIDERS', 'í¥êµ­ìƒëª…', 'í•‘í¬ìŠ¤íŒŒì´ë”ìŠ¤'],
        'í˜„ëŒ€ê±´ì„¤': ['HYUNDAIE&C', 'HILLSTATE', 'í˜„ëŒ€ê±´ì„¤', 'íìŠ¤í…Œì´íŠ¸'],
        'ì •ê´€ì¥': ['JUNGKWANJANG', 'REDSPARKS', 'KGC', 'GINSENG', 'ì •ê´€ì¥'],
        'IBKê¸°ì—…ì€í–‰': ['IBK', 'ALTOS', 'INDUSTRIALBANK', 'ê¸°ì—…ì€í–‰'],
        'GSì¹¼í…ìŠ¤': ['GSCALTEX', 'KIXX', 'GSì¹¼í…ìŠ¤', 'í‚¥ìŠ¤'],
        'ë„ë¡œê³µì‚¬': ['HIPASS', 'EXPRESSWAY', 'ë„ë¡œê³µì‚¬', 'í•˜ì´íŒ¨ìŠ¤'],
        'í˜í¼ì €ì¶•ì€í–‰': ['PEPPER', 'AIPEPPERS', 'í˜í¼ì €ì¶•ì€í–‰', 'í˜í¼']
    }
    for std, keys in mapping.items():
        if any(k in name_upper for k in keys): return std
    return name

def train_logic_constrained_model_v2():
    print("ğŸš€ Step 4-2: [ë…¼ë¦¬ ì œì•½] ë¬¼ë¦¬ì  ì •í•©ì„±(Physics-Informed) ê°•ì œ í•™ìŠµ (v2)...")

    BASE_DIR = os.path.dirname(os.path.abspath(__file__))

    # 1. ë°ì´í„° ì¤€ë¹„
    try:
        df = pd.read_csv(os.path.join(BASE_DIR, "kovo_analysis_ready.csv"))
    except FileNotFoundError:
        print("âŒ 'kovo_analysis_ready.csv' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # [ìˆ˜ì • 1] ì»¬ëŸ¼ ì´ë¦„ í†µì¼ (set_score -> score)
    # 03ë²ˆ ì½”ë“œì—ì„œ 'set_score'ë¡œ ì €ì¥í–ˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œ ì´ë¦„ì„ 'score'ë¡œ ë°”ê¿”ì¤˜ì•¼ ë’¤íƒˆì´ ì—†ìŠµë‹ˆë‹¤.
    if 'set_score' in df.columns:
        df.rename(columns={'set_score': 'score'}, inplace=True)

    # [ìˆ˜ì • 2] ì»¬ëŸ¼ ì´ë¦„ í†µì¼ (team_name -> tsname)
    # 03ë²ˆ ì½”ë“œë‚˜ ì›ë³¸ì— ë”°ë¼ ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ì•ˆì „ì¥ì¹˜ ì¶”ê°€
    if 'team_name' in df.columns:
         df.rename(columns={'team_name': 'tsname'}, inplace=True)

    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
    if 'tsname' not in df.columns or 'score' not in df.columns:
        print(f"ğŸš¨ ì»¬ëŸ¼ ëˆ„ë½ ì—ëŸ¬! í˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")
        print("   -> 'tsname'(ë˜ëŠ” team_name)ê³¼ 'score'(ë˜ëŠ” set_score)ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        return

    # ë‚ ì§œ ì •ë ¬
    df['game_date'] = pd.to_datetime(df['game_date'])
    df = df.sort_values(by=['game_date', 'game_num'])
    
    # íŒ€ ì´ë¦„ í‘œì¤€í™”
    df['team_std'] = df['tsname'].apply(get_standardized_name)

    # [ê°œì„  1] íŒ€ ìŠ¤íƒ¯ ì§‘ê³„ ë°©ì‹ ë³€ê²½ (ë‹¨ìˆœ í‰ê·  -> í•©ê³„ ê¸°ë°˜ ì¬ê³„ì‚°)
    num_cols = ['point', 'attackSuccessRate', 'ats', 'att', 'bs', 'ss', 'err', 'rs', 'rt']
    for c in num_cols:
        if c not in df.columns: df[c] = 0
        df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
    
    # 2) ê²½ê¸°ë³„/íŒ€ë³„ í•©ê³„ ê³„ì‚°
    # ì´ì œ 'score' ì»¬ëŸ¼ì´ í™•ì‹¤íˆ ìˆìœ¼ë¯€ë¡œ ì—ëŸ¬ê°€ ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    team_grp = df.groupby(['game_date', 'game_num', 'team_std'])
    
    team_stats = team_grp.agg({
        'point': 'sum',
        'ats': 'sum',   
        'att': 'sum',   
        'bs': 'sum',    
        'ss': 'sum',    
        'err': 'sum',   
        'rs': 'sum',    
        'rt': 'sum',    
        'home_team': 'first',
        'score': 'first'  # [í™•ì¸] ìœ„ì—ì„œ set_scoreë¥¼ scoreë¡œ ë°”ê¿¨ìœ¼ë¯€ë¡œ OK
    }).reset_index()

    # 3) ì§„ì§œ íŒ€ ì„±ê³µë¥  ê³„ì‚° (Weighted Rate)
    team_stats['attack_rate'] = team_stats.apply(lambda x: x['ats']/x['att'] if x['att']>0 else 0, axis=1)
    team_stats['receive_rate'] = team_stats.apply(lambda x: x['rs']/x['rt'] if x['rt']>0 else 0, axis=1)
    
    # í™ˆ/ì–´ì›¨ì´ êµ¬ë¶„
    team_stats['is_home_check'] = team_stats.apply(
        lambda r: r['team_std'] == get_standardized_name(r['home_team']), axis=1
    )

    # ì •ë ¬
    team_stats = team_stats.sort_values(['team_std', 'game_date'])

    # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ì´ë™ í‰ê· )
    metrics = ['attack_rate', 'bs', 'ss', 'err', 'receive_rate']
    
    for m in metrics:
        team_stats[f'roll_{m}'] = team_stats.groupby('team_std')[m].transform(
            lambda x: x.shift(1).rolling(5, min_periods=1).mean()
        )

    # íœ´ì‹ì¼ ê³„ì‚°
    team_stats['prev_date'] = team_stats.groupby('team_std')['game_date'].shift(1)
    team_stats['rest_days'] = (team_stats['game_date'] - team_stats['prev_date']).dt.days.fillna(4).clip(upper=14)

    # íƒ€ê²Ÿ(ìŠ¹íŒ¨) íŒŒì‹±
    def parse_target(row):
        try:
            s = list(map(int, str(row['score']).split(':')))
            if len(s) < 2: return pd.Series([None, None])
            
            my, opp = (s[0], s[1]) if row['is_home_check'] else (s[1], s[0])
            return pd.Series([1 if my > opp else 0, my - opp])
        except: return pd.Series([None, None])
    
    team_stats[['is_win', 'set_diff']] = team_stats.apply(parse_target, axis=1)
    team_stats = team_stats.dropna(subset=['is_win'])

    # ELO ë° ë§¤ì¹˜ì—… ë°ì´í„° ìƒì„±
    elo = {t: 1500 for t in team_stats['team_std'].unique()}
    matches = []
    
    sorted_games = team_stats.sort_values(['game_date', 'game_num'])
    
    for _, grp in sorted_games.groupby(['game_date', 'game_num']):
        if len(grp) != 2: continue
        
        h_row = grp[grp['is_home_check'] == True]
        a_row = grp[grp['is_home_check'] == False]
        if h_row.empty or a_row.empty: continue
        
        h, a = h_row.iloc[0], a_row.iloc[0]
        th, ta = h['team_std'], a['team_std']
        
        matches.append({
            'diff_elo': elo[th] - elo[ta],
            'diff_rest': h['rest_days'] - a['rest_days'],
            'diff_att': h['roll_attack_rate'] - a['roll_attack_rate'],
            'diff_block': h['roll_bs'] - a['roll_bs'],
            'diff_serve': h['roll_ss'] - a['roll_ss'],
            'diff_recv': h['roll_receive_rate'] - a['roll_receive_rate'],
            'diff_fault': h['roll_err'] - a['roll_err'], 
            'result_win': h['is_win'],
            'result_diff': h['set_diff']
        })

        # ELO ì—…ë°ì´íŠ¸
        w_h = h['is_win']
        exp_h = 1 / (1 + 10 ** ((elo[ta] - elo[th]) / 400))
        k_factor = 20
        elo[th] += k_factor * (w_h - exp_h)
        elo[ta] += k_factor * ((1 - w_h) - (1 - exp_h))

    # í•™ìŠµ ë°ì´í„° ì¤€ë¹„
    train_df = pd.DataFrame(matches).dropna()
    
    features = ['diff_elo', 'diff_att', 'diff_block', 'diff_serve', 'diff_recv', 'diff_fault']
    
    X = train_df[features]
    y = train_df['result_win']
    y_reg = train_df['result_diff']
    
    scaler = StandardScaler()
    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=features)
    
    print(f"\nğŸ“Š í•™ìŠµ ë°ì´í„°: {len(X)} ê²½ê¸°")
    
    # -------------------------------------------------------------------------
    # ğŸ”¥ [í•µì‹¬] ë…¼ë¦¬ì  ì œì•½ì´ ê±¸ë¦° ëª¨ë¸ í•™ìŠµ (Positive Constraints)
    # -------------------------------------------------------------------------
    print("ğŸ” ë…¼ë¦¬ì  ê°€ì¤‘ì¹˜ ê°•ì œ í•™ìŠµ ì¤‘...")
    
    # ë²”ì‹¤ ë¶€í˜¸ ë°˜ì „
    X_scaled_constrained = X_scaled.copy()
    X_scaled_constrained['diff_fault'] = -X_scaled_constrained['diff_fault'] 
    
    best_model = None
    best_score = 0
    
    c_params = [0.01, 0.05, 0.1, 0.5, 1.0, 5.0]
    
    for c in c_params:
        clf = LogisticRegression(C=c, fit_intercept=True)
        clf.fit(X_scaled_constrained, y)
        
        coefs = clf.coef_[0]
        # ëª¨ë“  ê³„ìˆ˜ê°€ 0ë³´ë‹¤ í°ì§€ í™•ì¸ (ê´€ìš© 0.0)
        if np.all(coefs >= -0.001): 
            score = np.mean(cross_val_score(clf, X_scaled_constrained, y, cv=5))
            if score > best_score:
                best_score = score
                best_model = clf
    
    if best_model:
        print(f"ğŸ† Best Model Found (Acc: {best_score*100:.2f}%)")
        print("   [ê°€ì¤‘ì¹˜ ë¶„ì„ - í´ìˆ˜ë¡ ìŠ¹ë¦¬ì— ê¸°ì—¬]")
        for f, w in zip(features, best_model.coef_[0]):
            real_w = w if f != 'diff_fault' else -w 
            print(f"   - {f}: {real_w:.4f}")
            
        reg_model = Ridge(alpha=1.0)
        reg_model.fit(X_scaled, y_reg)

        with open(os.path.join(BASE_DIR, "kovo_dual_model.pkl"), "wb") as f:
            pickle.dump({
                'classifier': best_model,
                'regressor': reg_model,
                'scaler': scaler,
                'features': features,
                'is_constrained': True
            }, f)
        print("\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ (kovo_dual_model.pkl)")
        
    else:
        print("ğŸš¨ ë…¼ë¦¬ì  ì •í•©ì„±ì„ ë§Œì¡±í•˜ëŠ” ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        clf = LogisticRegression()
        clf.fit(X_scaled, y)
        with open("kovo_dual_model.pkl", "wb") as f:
             pickle.dump({'classifier': clf, 'regressor': Ridge().fit(X_scaled, y_reg), 
                          'scaler': scaler, 'features': features, 'is_constrained': False}, f)
    # -------------------------------------------------------------
    # ğŸ§ª [ë³´ë„ˆìŠ¤] ìµœì ì˜ ìŠ¤ì½”ì–´ ì„ê³„ê°’(Threshold) ì°¾ê¸°
    # -------------------------------------------------------------
    print("\nğŸ” [Grid Search] ìµœì ì˜ ìŠ¤ì½”ì–´ êµ¬ë¶„ ê¸°ì¤€ íƒìƒ‰...")
    
    # ëª¨ë¸ ì˜ˆì¸¡ í™•ë¥  (Training set ê¸°ì¤€ì´ì§€ë§Œ ê²½í–¥ì„± íŒŒì•…ì—” ì¶©ë¶„)
    probs = best_model.predict_proba(X_scaled_constrained)[:, 1] # í™ˆ ìŠ¹ë¦¬ í™•ë¥ 
    
    # ì‹¤ì œ ìŠ¤ì½”ì–´ ì°¨ì´ (3, 2, 1, -1, -2, -3)
    # y_regëŠ” 'ì ìˆ˜ì°¨'ê°€ ì•„ë‹ˆë¼ 'ì„¸íŠ¸ì°¨'ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµí–ˆì–´ì•¼ ë” ì¢‹ì•˜ê² ì§€ë§Œ,
    # ì—¬ê¸°ì„œëŠ” y_reg(ì ìˆ˜ì°¨) ëŒ€ì‹  ì›ë³¸ ë°ì´í„°ì˜ 'result_diff'ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨.
    # í•˜ì§€ë§Œ train_dfê°€ ìˆìœ¼ë¯€ë¡œ ê±°ê¸°ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    actual_set_diffs = train_df['result_diff'].abs() # 3, 2, 1 (ì„¸íŠ¸ ì°¨ì´ëŠ” ì•„ë‹ˆê³  ì ìˆ˜ì°¨ë¼ ë¶€ì •í™•í•  ìˆ˜ ìˆìŒ)
    # ì •í™•íˆ í•˜ë ¤ë©´ 04ë²ˆ ë°ì´í„° ìˆ˜ì§‘ ë‹¨ê³„ì—ì„œ 'ì„¸íŠ¸ ìŠ¤ì½”ì–´(3:0 ë“±)'ë¥¼ ë³„ë„ ì»¬ëŸ¼ìœ¼ë¡œ ì €ì¥í–ˆì–´ì•¼ í•©ë‹ˆë‹¤.
    # ì§€ê¸ˆì€ 'ìŠ¹ë¥  ë¶„í¬'ë§Œ ì°ì–´ë³´ê² ìŠµë‹ˆë‹¤.
    
    results = pd.DataFrame({
        'prob': probs,
        'win': y,
        'score_diff': y_reg # ì ìˆ˜ì°¨
    })
    
    # ìŠ¹ë¦¬í•œ ê²½ê¸°ë§Œ ì¶”ì¶œ (í™•ë¥  0.5 ì´ìƒì¸ ê²½ìš°)
    wins = results[results['win'] == 1]
    
    # ì ìˆ˜ì°¨(score_diff)ê°€ í´ìˆ˜ë¡ 3:0ì¼ í™•ë¥ ì´ ë†’ìŒ.
    # ì ìˆ˜ì°¨ ë¶„ìœ„ìˆ˜(Quantile)ë¡œ ì—­ì¶”ì 
    
    # ìƒìœ„ 30% ì ìˆ˜ì°¨ì¸ ê²½ê¸°ë“¤ì˜ í‰ê·  ìŠ¹ë¥  -> 3:0 ê¸°ì¤€
    # í•˜ìœ„ 30% ì ìˆ˜ì°¨ì¸ ê²½ê¸°ë“¤ì˜ í‰ê·  ìŠ¹ë¥  -> 3:2 ê¸°ì¤€
    
    t_shutout = wins[wins['score_diff'] >= wins['score_diff'].quantile(0.7)]['prob'].mean()
    t_close = wins[wins['score_diff'] <= wins['score_diff'].quantile(0.3)]['prob'].mean()
    
    print(f"   ğŸ“Š ë°ì´í„° ë¶„ì„ ê²°ê³¼:")
    print(f"      - ì••ìŠ¹(3:0) ê²½ê¸°ë“¤ì˜ í‰ê·  ìŠ¹ë¥ : {t_shutout*100:.1f}%")
    print(f"      - ì ‘ì „(3:2) ê²½ê¸°ë“¤ì˜ í‰ê·  ìŠ¹ë¥ : {t_close*100:.1f}%")
    
    # ì¤‘ê°„ê°’ìœ¼ë¡œ ê¸°ì¤€ ì„¤ì •
    suggest_t2 = (t_shutout + 0.60) / 2 # ë³´ì •
    suggest_t1 = (t_close + 0.50) / 2
    
    print(f"   ğŸ’¡ ì¶”ì²œ ì„ê³„ê°’: {suggest_t1*100:.0f}% (3:2 vs 3:1) / {suggest_t2*100:.0f}% (3:1 vs 3:0)")
if __name__ == "__main__":
    train_logic_constrained_model_v2()